# This is a basic workflow to help you get started with Actions

name: Pyspark

# Controls when the workflow will run
on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
  schedule:
    - cron: '0 */24 * * *'

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3

      #setup java and python
      - uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          cache: 'pip'
      - run: pip install -r requirements.txt
      - uses: actions/setup-java@v1
        with:
          java-version: '11'
      - uses: vemonet/setup-spark@v1
        with:
          spark-version: '3.2.1'
          hadoop-version: '3.2'
      - run: spark-submit --version

      #setup spark
      - uses: vemonet/setup-spark@v1
        with:
          spark-version: '3.2.1'
          hadoop-version: '3.2'
          scala-version: '2.13'
          spark-url: 'https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2-scala2.13.tgz'

      #setup jupyter notebook
      - id: jupyter 
        name: Jupyter Notebook Execution
        run: jupyter execute sparktest.ipynb
        shell: bash
